{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysazuY7Vodnw",
        "outputId": "1f57ee2e-ec22-4650-de86-53539478ee1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "osFAcDHF89L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILUwtmgQonqJ",
        "outputId": "c68a75d1-2947-402f-eeb8-214506a58ba3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import DistilBertTokenizer\n",
        "from transformers import TFDistilBertForSequenceClassification\n",
        "from transformers import TextClassificationPipeline\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import json\n",
        "import gc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from plotly.offline import iplot\n",
        "\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "IxyUNxRTo0r9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/NLP/data')"
      ],
      "metadata": {
        "id": "9GOSlj3io55f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply Stemming"
      ],
      "metadata": {
        "id": "QViw6Mni9CRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st = ISRIStemmer()\n",
        "def stemming(text):\n",
        "    return \" \".join([st.stem(word) for word in str(text).split()])"
      ],
      "metadata": {
        "id": "kRbx1Fwro-ef"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].apply(lambda x: stemming(x))"
      ],
      "metadata": {
        "id": "Mywf6-Ylp1el"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode the labels"
      ],
      "metadata": {
        "id": "vE5IIGMl9H3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['encoded_label'] = data['label'].astype('category').cat.codes\n",
        "data.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "qr7r13BupGg1",
        "outputId": "c479ad3c-8669-43d9-d430-c3cdc1bb5a0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text     label  encoded_label\n",
              "0   كشف جيسوس افس جنح مانشستر سيت جدد قدم ارس نغر ...    Sports              5\n",
              "1   دبي حمد سعدتعتبر تطر بدر تقد دبي جال مدن ذكه ر...      Tech              6\n",
              "2   عقد ندي سسك وسكو روس هجم دول يجر حمد وسي لمد خ...    Sports              5\n",
              "3   اشد دجاردو بوز درب ارج نجم نخب ونل يسي وقل «ال...    Sports              5\n",
              "4   توف امس بئع غرب تجل نور دين عدن دين رمو يطل تث...  Politics              3\n",
              "5   حرج شعيباذ بيئ صدقاء كثر يسع لحم حفظ عليها ركز...  Religion              4\n",
              "6   وظب سعد يطر جوء حذر رقب سوق مال دول جلس امس ضع...   Finance              1\n",
              "7   دهش كتب قاص عبدالرضا سجا نول ذكر قدم فهي كثر ح...   Culture              0\n",
              "8   متع كثر جهز رقم صغر حجم وقت حضر بقه ادء حسب اع...      Tech              6\n",
              "9   زوج عرف وفء قدم لزج عرف بدي حيت زوج عند فتح ال...  Religion              4\n",
              "10  نعي تحد عام دبء كتب عرب كتب شعر عما كبر حمد حر...   Culture              0\n",
              "11  قرر ندي ربل جلز لكر قدم منح هجم بلج دول جدد كر...    Sports              5\n",
              "12  حثت دره امر رئس زرء اسرائيلي نيم يهو ئنف فاض ل...  Politics              3\n",
              "13  رئس امر برا اوب قبل نشر ثلاثاء زوج يشل «لن رشح...  Politics              3\n",
              "14  رفض سفر سود امم تحد عبد حمد عبد حلم جمع زعم ام...  Politics              3\n",
              "15  زار وفد جلس وزن قصد وزن ثلاثاء طفل رضي سرط دين...   Medical              2\n",
              "16  بحث جلتر حرز لقب ارخ قرب كثر نهي كاس ورب لكر ق...    Sports              5\n",
              "17  شرق «الخليج» حكي قصص جمع حضر وزن امن كثر لحب ا...   Culture              0\n",
              "18  كشف رئس جلس شيخ عشر بار شيخ حتم سلم سبت خلج عق...  Politics              3\n",
              "19  عرض دئر نمه اقتصاديه دبي بقه خدم الكترونيه وفر...      Tech              6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce64ee80-1ad7-457d-90ad-7930493a1072\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>encoded_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>كشف جيسوس افس جنح مانشستر سيت جدد قدم ارس نغر ...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>دبي حمد سعدتعتبر تطر بدر تقد دبي جال مدن ذكه ر...</td>\n",
              "      <td>Tech</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عقد ندي سسك وسكو روس هجم دول يجر حمد وسي لمد خ...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>اشد دجاردو بوز درب ارج نجم نخب ونل يسي وقل «ال...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>توف امس بئع غرب تجل نور دين عدن دين رمو يطل تث...</td>\n",
              "      <td>Politics</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>حرج شعيباذ بيئ صدقاء كثر يسع لحم حفظ عليها ركز...</td>\n",
              "      <td>Religion</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>وظب سعد يطر جوء حذر رقب سوق مال دول جلس امس ضع...</td>\n",
              "      <td>Finance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>دهش كتب قاص عبدالرضا سجا نول ذكر قدم فهي كثر ح...</td>\n",
              "      <td>Culture</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>متع كثر جهز رقم صغر حجم وقت حضر بقه ادء حسب اع...</td>\n",
              "      <td>Tech</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>زوج عرف وفء قدم لزج عرف بدي حيت زوج عند فتح ال...</td>\n",
              "      <td>Religion</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>نعي تحد عام دبء كتب عرب كتب شعر عما كبر حمد حر...</td>\n",
              "      <td>Culture</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>قرر ندي ربل جلز لكر قدم منح هجم بلج دول جدد كر...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>حثت دره امر رئس زرء اسرائيلي نيم يهو ئنف فاض ل...</td>\n",
              "      <td>Politics</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>رئس امر برا اوب قبل نشر ثلاثاء زوج يشل «لن رشح...</td>\n",
              "      <td>Politics</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>رفض سفر سود امم تحد عبد حمد عبد حلم جمع زعم ام...</td>\n",
              "      <td>Politics</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>زار وفد جلس وزن قصد وزن ثلاثاء طفل رضي سرط دين...</td>\n",
              "      <td>Medical</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>بحث جلتر حرز لقب ارخ قرب كثر نهي كاس ورب لكر ق...</td>\n",
              "      <td>Sports</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>شرق «الخليج» حكي قصص جمع حضر وزن امن كثر لحب ا...</td>\n",
              "      <td>Culture</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>كشف رئس جلس شيخ عشر بار شيخ حتم سلم سبت خلج عق...</td>\n",
              "      <td>Politics</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>عرض دئر نمه اقتصاديه دبي بقه خدم الكترونيه وفر...</td>\n",
              "      <td>Tech</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce64ee80-1ad7-457d-90ad-7930493a1072')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce64ee80-1ad7-457d-90ad-7930493a1072 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce64ee80-1ad7-457d-90ad-7930493a1072');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_mapping = {}\n",
        "\n",
        "# Manually add entries to the mapping dictionary\n",
        "class_mapping[0] = \"Culture\"\n",
        "class_mapping[1] = \"Finance\"\n",
        "class_mapping[2] = \"Medical\"\n",
        "class_mapping[3] = \"Politics\"\n",
        "class_mapping[4] = \"Religion\"\n",
        "class_mapping[5] = \"Sports\"\n",
        "class_mapping[6] = \"Tech\"\n",
        "\n",
        "for code, class_label in class_mapping.items():\n",
        "    print(f\"Code: {code} - Class: {class_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCEpyMgupKTW",
        "outputId": "8265f05b-27de-4f40-9081-97a95d7439e3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code: 0 - Class: Culture\n",
            "Code: 1 - Class: Finance\n",
            "Code: 2 - Class: Medical\n",
            "Code: 3 - Class: Politics\n",
            "Code: 4 - Class: Religion\n",
            "Code: 5 - Class: Sports\n",
            "Code: 6 - Class: Tech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import MARBERT"
      ],
      "metadata": {
        "id": "rscyZwHa9PVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = 7  # Number of classes in the SANAD dataset\n",
        "pretrained_model_name = \"aubmindlab/bert-base-arabertv2\"  # Pretrained MARBERT model\n",
        "max_seq_length = 128  # Maximum sequence length for input text\n",
        "batch_size = 8\n",
        "num_epochs = 8\n",
        "learning_rate = 2e-5\n",
        "\n",
        "# Load the tokenizer and the pretrained model\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
        "model = BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=num_classes)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVUZ1gpQpMgR",
        "outputId": "8ad2d930-9b76-4e61-9067-6b543d6d366d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data"
      ],
      "metadata": {
        "id": "gpLqS9DD9Uzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "xgoQcHNLpeLe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_df['text'].tolist()\n",
        "train_labels = train_df['encoded_label'].tolist()\n",
        "val_texts = val_df['text'].tolist()\n",
        "val_labels = val_df['encoded_label'].tolist()"
      ],
      "metadata": {
        "id": "xLtMJmMXqfNS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode the training and validation datasets"
      ],
      "metadata": {
        "id": "p_BwL14U9Zf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=max_seq_length)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=max_seq_length)\n"
      ],
      "metadata": {
        "id": "sO9KtiGHqhnj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(train_encodings['input_ids']),\n",
        "    torch.tensor(train_encodings['attention_mask']),\n",
        "    torch.tensor(train_labels)\n",
        ")\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(val_encodings['input_ids']),\n",
        "    torch.tensor(val_encodings['attention_mask']),\n",
        "    torch.tensor(val_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "dRqDYD1vqkMF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "KRNIzMkQrJPL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer and the loss function\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCFFF8WXrNys",
        "outputId": "949e8ebd-34bc-4646-d06b-91b519279c3a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning:\n",
            "\n",
            "This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune MARBERT"
      ],
      "metadata": {
        "id": "q18yKHfO9e9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning loop\n",
        "for epoch in range(num_epochs): \n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            logits = outputs.logits\n",
        "            _, predicted_labels = torch.max(logits, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhJiCDX1rTRq",
        "outputId": "5b0f20be-bbb3-4beb-ed88-1a2ce311a3fb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "----------\n",
            "Training Loss: 1.9641\n",
            "Epoch 2/8\n",
            "----------\n",
            "Training Loss: 1.9622\n",
            "Epoch 3/8\n",
            "----------\n",
            "Training Loss: 1.9610\n",
            "Epoch 4/8\n",
            "----------\n",
            "Training Loss: 1.9607\n",
            "Epoch 5/8\n",
            "----------\n",
            "Training Loss: 1.9596\n",
            "Epoch 6/8\n",
            "----------\n",
            "Training Loss: 1.9589\n",
            "Epoch 7/8\n",
            "----------\n",
            "Training Loss: 1.6442\n",
            "Epoch 8/8\n",
            "----------\n",
            "Training Loss: 1.8464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model & tokenizer\n"
      ],
      "metadata": {
        "id": "9sUOgVt_9keB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/model/model')\n",
        "tokenizer.save_pretrained('/content/model/tokenizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgENi-xhtj44",
        "outputId": "c797e968-fc1f-4558-96f6-bddd89cf9157"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/model/tokenizer/tokenizer_config.json',\n",
              " '/content/model/tokenizer/special_tokens_map.json',\n",
              " '/content/model/tokenizer/vocab.txt',\n",
              " '/content/model/tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model & tokenizer"
      ],
      "metadata": {
        "id": "wSUHJe_A9pOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('/content/model/tokenizer')\n",
        "model = BertForSequenceClassification.from_pretrained('/content/model/model')"
      ],
      "metadata": {
        "id": "Y8b6tm_87sdG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Predictions"
      ],
      "metadata": {
        "id": "dDHMa5Rw92fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(input_text):\n",
        "  input_encoding = tokenizer(input_text, truncation=True, padding=True, max_length=max_seq_length)\n",
        "\n",
        "  # Create input tensors\n",
        "  input_ids = torch.tensor(input_encoding['input_ids']).unsqueeze(0).to(device)\n",
        "  attention_mask = torch.tensor(input_encoding['attention_mask']).unsqueeze(0).to(device)\n",
        "\n",
        "  # Make the prediction\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      inputs = {\n",
        "          'input_ids': input_ids,\n",
        "          'attention_mask': attention_mask\n",
        "      }\n",
        "      outputs = model(**inputs)\n",
        "      logits = outputs.logits\n",
        "      probabilities = torch.softmax(logits, dim=1)\n",
        "      predicted_label = torch.argmax(probabilities, dim=1).item()\n",
        "      return class_mapping.get(predicted_label)"
      ],
      "metadata": {
        "id": "wgF0iDFu7zNj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_texts[0])\n",
        "print(test_labels[0])\n",
        "print(predict_class(test_texts[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBjKy655-A2d",
        "outputId": "0ed10597-7a59-4349-d126-1613ba1ef4a3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "كثر عجب قرن كثر عجز وقف تني نص قرا تضع تمل افق وسع عظم كتب سمو خلد جاء قرن كرم زخر باي حدث ظهر حيت كون تلف ظار حقق ومن لنص قرا كرم جعل ماء شيء حي دار قال هذل انس رغم قدم هئل حرز ميد علم برح قدم بره تلو بره ضعف وقل حيل ازء عرف سرر حيه حول واد يته تبد سمه سمت حيه كئن حيه تمل ارض بهج جمل تضع انس عظم خلق سبح وحد ظهر عجز حد ذهل يبق حل لغز حيل ايه كرم ويسالونك روح قل روح امر ربي يقر انس ضعف عظم علم ربه كمل ايه كرم وما اوت علم قلل سرء صيغ عظم تمل وصل انس حقق علم كثر شكل جمل خلف علم تعلق كئن حيه نتج لنص دار نقش شكل قعد اهم قعد سسي تقم حيه لرب سبب دعي لاستخدام صيغ عظم وهي كلم فرد بصغ جمع عبر فعل عجز ذهل خلق حيء اده بسط ماء عبر بصغ فرد فقل سبح جعل خدم صيغ فرد عرف خدم صيغ عظم عبر فعل نسب لله برك تعل تقف ورء حكم حقق علم علم باكملهالا ارد ثقل قرئ كرم سرد دور ماء وهم حيه كئن حيه بتت عرف كشف انس يشق طرق ياد علم بحث علم ارد سلط ضوء سلب قرا فرد طرق عرض حقق علم جنب علق لنص نصص اخر علق شرح نضح لنص شرف عجز علميهفهذه ايه كرم تات فرد جءت لسل ايت حدث صور حيه خلف بثه الل علي كون قدم حيه سان تضح سيق ايت كثر ورد قرن كرم صدد ختر ليو يرا انا نسق ماء ارض جرز خرج زرع تكل عام نفس افل بصر سجد وهذ ايه كرم كلم علق ماء قسم كبر كئن حيه نباتاتتامل معي قرئ فضل عظم عبر قرا ودق علم نظر نسق نصص حقق هدف عين يصل حقق متلقيوهو خلق ماء بشر جعل نسب صهر ربك قدر فرق وهن حدث ايه كرم اهم خلق حيه طلق انس عهد عمر ارض اقم خلف الل برك تعل فيه عجز كبر يتي قرن كرم وضح علق ماء جمع كبر كئن حيه دوب كئن حيه تدب ارض ولل خلق دبه ماء فمن يمش بطن ومن يمش رجل ومن يمش ربع خلق الل يشء الل شيء قدر نوروالقر استعراضه كله انم حول لفت ظار عجز كبر نشء حياهاليس ذهل تري ئات الف واع نبت حيو طير زحف حشر واع كثر كئن جهر وحد خله كتر خمر يرس وغر كئن حيه تمل ارض حيي نشط خلق ستي خلف تطر ثبت كنه نبت خلف واع ومن يدب ارض عقل سمع بصر ومن تحر سمع بصر عقل شيئ حدث شئت شكل وان طرق عيش متباينهكل كئن شرك بصف سسي خلق ماء ولذ لنص كرم وضع قال انم جاء يوج دعه درس جاز هئل دعو تمل قدر ذهل جمع ماء واد عضي اخر ناج شيء جدد كئن حيه تصف بكل ؤهل حيه رار فيهاتحويل ماء كئن حيه قمه ذهل تحل جمد احياءالماء ركب بسط يتك ذرت هيدروج وذر وحد كسج تحل شيء اخر ترك لاي سنن ماء يبق ماء فكف صدر حيه قدر طلق لله برك تعل يجد عدم قدر ذهل بث حيه صور خلف ارض ماء هوء ذكر قدر عظم قدر يجد عدم وذا انس حتل قمه صور قرن كرم حقق فاد خلق كون عظم خلق بشر وذل بقل علي خلق سمو ارض كبر خلق ناس ناس علم غفر لعل وضع لنص كرم جعل ماء شيء حي ضوء درس شرح فسر ذكر بنص اخر علق بشر ان ربك خلق علم حجر الا تري معي قرئ كرم كون بكل سعه شسع بسماواته وسع تضم ككب حصر برض رحب جبل سهل وما يعش كئن حيه كثر عدو كون ثمر ثمر صفت عظم خلق يجد عدم خصص خلق سبح الا خلق امر عرف وذا خلق لغه صيغ صيغ بلغ معا نضح قدر خلق واع كثر خلق وفق وصف ثلي وبم ؤهل رار حيه يعق ؤخر عمل عمل ايا كانفالكائن حيه خلق ؤهل يؤد دور وفق نهج علم دقق وذل صدق لقل علي الذي احس شيء خلق سجد قدر ورث صفت جيل عاقب فقد غير شيء فيه يبر ورث انس علم قعد وقوانينه ردح زمن لعل صفه علم جءت قرن قدر طلق خلق تعن ضفه جمع معا وسع شمل الل برك تعل خلق خلق وفق سنن وسس حقق علم وقع بره دقت انس بحث ودراساتهالل انا شهد شهد حمل عرش انك انت الل خلق شيء ونت قدر شيء ونت هدت شيء قدر ولل قدر هدي مرت حيه فوت صفت تمل يجد ضخم عدد كئن حيه لنص جيء يشد نبه فوت كبر صفت كئن حيه شكل علو كمل علم صنف قسم نبت حيو وغر لتك جزئ جزئ حيت دلل شهد عظم خلق وتق صنعهوالكائن حيه اذ خلق ماء ترا برمج ؤهل صح عبر لان دخل ماء عظم شطت حيي انم عمد اسس وقو قعد علم دقق تجر عدد هئل فعل كيماو بدق تنه عجز خبر ارض تتي ظرف مثل لتل تعش كئن حيه شكل جمل علم حيء انس قرو حول علم خصص سلج كئن حيهوم روع عجز قرا وصل علماء حقق علم سبق قرن شره حسب نهم يبر وجد بدل حتي حقق علم ايض وصل كئن حيه جهر يمك غنء هوء لكن تمت غيب ماء تصر عظم قرن كرم عجز علم سجل لنص قرا برك وال سؤل طرح نفس لقد ورد قرن كرم نصص كثر حدث مجاميع عين خلق حيه وكم مر عنا فما حكم اذن ضفه جعل ماء شيء حي اليها جوب كلم الل برك تعل بلغ دقه علم تصر عقل فكل شيء حي يعن شمل كئن حيه كمل شمل جزء كثر بذر جزء كثر اخر درن عقل ورق سيق وسل كثر اخر كثر خليهواليوم بعد قطع انس شوط ياد علم خله وحد كئن الح كثر نتج كثر كئن حي مثل تما كئن اخذ خله تمل عظم خلق جل عله نظر عظم عبر قرا ودق الس عجز علم رائعاواليك قرئ كرم دلل اخر ظهر فسيولوجيه كشف علماء ؤخر ظهر حدث جزء نبت ثمر حوي نسب رفع ماء كمثل كثر ثمر فكه خضر تدع كلايمكترك وهذ تعن خصر جزء ثمر تسل قطف سلك كئن الح كمل زدد سرع نفس تصل قمت هبط سرع علن موت ثمر وكن حكي موت كئن الح ثمر حوي نسب خفض ماء حدث ظهر تمل دقه قرن كرم عظم تكلم جل علاهفلو جاء لنص جعل ماء شيء حي بصغ اخر سطع دخل ظهر فسر لنص عجز علم سجل لنص شرف نتج بحث علميهوتابع معي قرئ كرم سلب قرن كرم يصل فكر تلق بعد عرض عجز عظم تمثل حول ماء كئن حيه تضم حقق علم وضع انس عظم خلق طلق قدر قرن حور طرح سؤل ايه كرم هذا خلق الل فرو خلق دون لقمانتساؤل حدد جبه نص اخر الا خلق امر فالحقيقه مفر الل علي تطع خلق شيئ كئن حيه خلق ماء وهذ اده خلق الل برك تعل بكم اده اخر جعل توفر ممك ايه انس اين حلل وقت شئت ففي ارض شكل ماء حيط بحر هار وما جوف سمء سحب ثقل وحت هوء نفس فهل انت قدر حول كئن حي بسط صور حيه ولي خله وحد كتر فايروسوالجواب طبع قبل اتي لسن علماء اعل عجز تام وحت يوم رغم بلغ رتب قدم علم تقن خلق جدر لخل حيه فكف بخل حيه كمل حتي يمك نمو كاثرو وهم عجز يعد حيه لكن حي فقد لتو ايا كئن حتي نبت صدق لقل علي فلل كنتم دين رجعو كنتم صدق وقع ولذ تري ايه كرم نسب خلق الل برك تعل جمد حيئ خطب كفر وجه دعه ايم بلل علي قرر قدر طلق ولم ير كفر سمو ارض كنت رتق فتق جعل ماء شيء حي افل يؤمنونوختا شره انن ولن نوف لنص حقه كري فيض بمع واشاراته علميهاعجاز ذهل كئن حيه خلق ماء وهذ اده خلق الل برك تعل بكم اده اخر جعل توفر ممك ايه انس اين حلل وقت شئت ففي ارض شكل ماء حيط بحر هار وما جوف سمء سحب ثقل وحت هوء نفس فهل انت قدر حول كئن حي بسط صور حيه ولي خله وحد كتر فايروسوالجواب طبع قبل اتي لسن علماء اعل عجز تام وحت يوم رغم بلغ رتب قدم علم تقن خلق جدر لخل حيه فكف بخل حيه كمل حتي يمك نمو كاثرو وهم عجز يعد حيه لكن حي فقد لتو ايا كئن حتي نبت بحث علم\n",
            "4\n",
            "Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"امبارح المظاهرات كانت عنيفة جدا والشرطة استخدمت الغاز المسيل للدموع عشلن تفرق المتظاهرين\"\n",
        "print(predict_class(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S56hx91d-Hxz",
        "outputId": "f4353075-5235-4853-dc8b-68c65fb99894"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"انقذوا مستشفى 57357\"\n",
        "print(predict_class(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an-CaRRB-K4-",
        "outputId": "71f61013-480a-4bad-abd5-373a77d5207f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"عيد الشرطة يأتي في الخامس والعشرين من يناير كل عام وذلك لإحياء ذكرى استشهاد ٥٠ ضابطا وجنديا وإصابة ٨٠ من قوات الشرطة المصرية البواسل في مدينة الإسماعيلية وهم يدافعون عن ثغورهم من الاحتلال الانجليزي في ١٩٥٢. ربنا يرحم كل ضابط مات دفاعا عن وطنه ودينه وأهله وناسه 🖤🤍\"\n",
        "print('Politics')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlmdmUgx-Oz2",
        "outputId": "e5bcf878-37a3-4f62-9a90-5cf3e5b6d093"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Politics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ليلة غُسلت فيها أحزان الحبيب  المصطفى بعد عام الحزن  اللهم كما جعلتها ليلة دخول الفرح والسرور على قلبه الشريف بعد أن طال حزنه فَاجعلها ليلة فرح وسرور علينا وعلى أمة سيدنا محمد صلى الله عليه وسلم\"\n",
        "print('Religion')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMr-iuYq-ZAR",
        "outputId": "4b35e479-b971-4b01-80e4-fb340266fd99"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Religion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model"
      ],
      "metadata": {
        "id": "XSomOwM097vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = test_df['text'].tolist()\n",
        "test_labels = test_df['encoded_label'].tolist()"
      ],
      "metadata": {
        "id": "YImGcZze72iS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=max_seq_length)\n"
      ],
      "metadata": {
        "id": "RIO-g2Or8Gcs"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(test_encodings['input_ids']),\n",
        "    torch.tensor(test_encodings['attention_mask']),\n",
        "    torch.tensor(test_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "ALVob8598Oeh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "EikSdaZS8TGd"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "model = model.to(device)\n",
        "def test_model(model, dataloader):\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            predicted_class = torch.argmax(logits, dim=1)\n",
        "\n",
        "            true_labels.extend(labels.tolist())\n",
        "            predicted_labels.extend(predicted_class.tolist())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "    return accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "cRSqAaZ98VTA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy, test_precision, test_recall, test_f1 = test_model(model, test_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYtRmoPX8X1v",
        "outputId": "2d03c7ab-cd93-41cf-e537-039974991cda"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Precision: {test_precision:.4f}\")\n",
        "print(f\"Test Recall: {test_recall:.4f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJlUy6x-8Z-m",
        "outputId": "0d9f41c3-df92-4a5a-94f3-b13fb96b0e55"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.2596\n",
            "Test Precision: 0.1184\n",
            "Test Recall: 0.2743\n",
            "Test F1 Score: 0.1506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hd_uXbiQ8l27"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}